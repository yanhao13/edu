<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
    <head>
    <meta name="google-site-verification" content="iYVjQd933sGW2zlmYbdFxnSaklGJkVr_2343c48_6PQ" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link rel="shortcut icon" href="./images/doge.ico">
<!--    <link href="main.css" media="all" rel="stylesheet">-->
    <link rel="stylesheet" href="jemdoc.css" type="text/css">
    <title>Di CHANG | 常迪</title>
    </head>

<body>


<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1 style="color:#FF0000">Di (Kilian) Chang</h1><h1>
					<h1 style="color:#FF0000">常迪</h1><h1>
				</h1></div>

				<h3>CS Ph.D.  @ <a href="https://www.usc.edu/" target="_blank">University of Southern California</a></h3>
				<!-- <h3>Research Scientist Intern @ <a href="https://www.tiktok.com/en/" target="_blank">TikTok</a></h3> -->
<!--                <h3>University of Southern California</h3>-->
				<p>
					<a href="https://www.cs.usc.edu/" target="_blank">Department of Computer Science</a> <br>
					<a href="https://viterbischool.usc.edu/" target="_blank">Viterbi School of Engineering</a><br>
					<a href="https://www.usc.edu/" target="_blank">University of Southern California</a> <br>

<!--					Rm B06, Hedco Neurosciences Building, 3641 Watt Way, Los Angeles, CA 90089-2520, USA <br>-->

					Email1: dichang at usc dot edu (primary) <br>
					Email2: dchang at ict dot usc dot edu <br>
					Email3: di dot chang at bytedance dot com
				</p>
				<p> <a href="https://scholar.google.com.hk/citations?hl=en&user=68wkMTgAAAAJ" target="_blank"><img src="./pics/google_scholar3.png" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/Boese0601" target="_blank"><img src="./pics/github_s.jpg" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://twitter.com/DiChang10" target="_blank"><img src="./images/twitter.png" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://www.instagram.com/kiliandi10/" target="_blank"><img src="./files/ins.png" height="40px" style="margin-bottom:-3px"></a>
                    <a href="https://www.linkedin.com/in/di-chang-004784206/" target="_blank"><img src="./pics/LinkedIn2.png" height="40px" style="margin-bottom:-3px"></a>
                    <a href="files/CV_Di.pdf"><img src="./pics/cv2.png" height="40px" style="margin-bottom:-3px"></a>
					&nbsp &nbsp
					<!-- <a href="#C1">[<font <font size="3" color="#CB4335"><b>About Me</b></font>] </a> -->
					<a href="#C2">[<font size="3" color="#CB4335"><b>News</b></font>]</a>
					<a href="#edu">[<font size="3" color="#CB4335"><b>Education</b></font>]</a>
					<a href="#C3">[<font size="3" color="#CB4335"><b>Publications</b></font>]</a>
					<a href="#C4">[<font size="3" color="#CB4335"><b>Experience</b></font>]</a></li>
				</p>
			</td>
			<td>
				<img src="./images/dichang.png" border="0" width="230"><br>
<!--				<img src="pics/cover.png" border="0" width="540"><br>-->
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<!--<style>-->
<!--ul-->
<!--{-->
<!--	list-style-type:none;-->
<!--	margin:0;-->
<!--	padding:0;-->
<!--}-->
<!--li a:hover {-->
<!--    background-color: #555;-->
<!--    color: white;-->
<!--}-->

<!--</style>-->


<!--   #0F73B6-->

<h2><a id="C1" ><font color="#CB4335">About Me</font></a></h2>
<p> <a href="https://www.cs.usc.edu/"><img src="./pics/USC_logo.png" height="100px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="https://www.tiktok.com/en/"><img src="./images/TikTok.jpeg" height="100px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="https://www.tum.de/en/"><img src="./images/TUM.jpg" height="100px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="https://www.epfl.ch/en/"><img src="./images/EPFL.png" height="120px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp &nbsp
	<a href="https://hkust.edu.hk/home"><img src="./images/HKUST.jpg" height="100px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<br>
	<br>
	<!-- <a href="https://www.microsoft.com/en-us/research/"><img src="./pics/microsoft_logo.jfif" height="95px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp &nbsp
	<a href="https://www.uii-ai.com/en/"><img src="./pics/UII_logo33.png" height="98px" style="margin-bottom:-3px"></a>&nbsp &nbsp &nbsp
	<a href="http://flexiv.com/"><img src="./pics/flexiv_logo.jfif" height="105px" style="margin-bottom:-3px"></a> -->

</p>
<p>
	<b>I'm currently looking for research intern working on GenAI/3D Rendering/Human Image & Video Editing/Diffusion Model during 2024 summer. If you have any openings or opportunities to refer, please don't hesitate to contact me!</b>
</p>
<p>I am a <strike>first-year</strike> second-year Ph.D. student in the Department of Computer Science at <a  href="https://www.cs.usc.edu/">University of Southern California</a> (USC) with Prof. <a  target="_blank" href=https://people.ict.usc.edu/~soleymani/ target="_blank" rel="external">Mohammad Soleymani</a> of <a  href="https://www.ihp-lab.org/">IHP-Lab</a>.
	I was a Research Scientist Intern at TikTok-ByteDance AI Lab US, Intelligent Creation Team, working with Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external"> Yichun Shi </a> and Dr. <a target="_blank" href= https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en  rel="external">Xiao Yang</a> during 2023 summer.
	<!-- I work closely with Prof. <a  target="_blank" href=https://xiaolonw.github.io/ target="_blank" rel="external"> Xiaolong Wang </a> from <a  target="_blank" href=https://ucsd.edu/ target="_blank" rel="external"> UC San Diego </a>. -->
</p>
	Before that, I spent four wonderful years during my undergraduate at <a href="https://en.dlut.edu.cn/">Dalian University of Technology</a> and <a href=https://www.tum.de/en/ target="_blank" >Technical University of Munich</a>, studying Informatics and Information Engineering.
	I'm honored to be advised by Prof. <a  target="_blank" href=https://www.niessnerlab.org/members/matthias_niessner/profile.html target="_blank" rel="external"> Matthias Niessner </a> and
	Dr. <a  target="_blank" href=https://aljazbozic.github.io/ target="_blank" rel="external"> Aljaž Božič </a> during my praktikum at <a  target="_blank" href="https://www.niessnerlab.org/" target="_blank" rel="external">Visual Computing Group</a>.
	I spent a wonderful summer in 2022 with Dr. <a  target="_blank" href=https://sites.google.com/view/tong-zhang rel="external"> Tong Zhang </a>
	and Prof. <a  target="_blank" href=https://people.epfl.ch/sabine.susstrunk?lang=en target="_blank" rel="external"> Sabine Süsstrunk</a> at EPFL CS and in 2021 with Prof. <a  target="_blank" href=https://www.danxurgb.net/index.html target="_blank" rel="external"> Dan Xu </a> at HKUST CSE.
</p>
	I'm interested in Computer vision, Multi-View Stereo and Neural Rendering. My current research focuses include:
<ul>
	  <li>3D Vision, especially Multi-View Geometry and Scene Reconstruction with Deep Learning approaches. </li>
	  <li>Video Generation and View Synthesis with Generative Models(DDPM).</li>
	  <li>Multimodal Machine Learning.</li>
	  <li>Facial Expression Analysis and Affective Computing.</li>
<!--	  <li>Effortless AI (how generative models reduce human effort and boost discriminative models)</li>-->
	</ul>
<!--<ul>-->
<!--	  <li>Causal Explainable AI ((1) Understanding reasoning logic and causality of Neural Networks (NN) (2) Use explanation as feedback to help improve the performance of the original NN.) </li>-->
<!--	  <li>Interpretable human-AI interaction (understanding AI models beyond accuracy, such as disentangled representation learning, human-NN knowledge exchange, steerability, generalization, fairness and bias)</li>-->
<!--	  <li>Humanoid Neural Network (simulating human cognitive learning ability (Imagination, Reasoning, Visual Recognition) by using various learning algorithms (Generative models, Representation Learning, Graph Neural Network, Contrastive Learning, etc.)</li>-->
<!--	  <li>Effortless AI (how generative models reduce human effort and boost discriminative models)</li>-->
<!--	</ul>-->

<!--	I'm interested in Machine Learning, Computer vision, and their applications towards Artificial General Intelligence (AGI). My current research focuses include:-->
<!--<ul>-->
<!--	  <li>interpretable human-AI interaction (interpretability, steerability, disentangled representation learning)</li>-->
<!--	  <li>generative models (data augmentation, how generative models boost discriminative models)</li>-->
<!--	  <li>graph neural networks (structure and relationship learning)</li>-->
<!--	  <li>visual reasoning, attention and saliency (cognitive learning, eye tracking)</li>-->
<!--	</ul>-->
<!--<p>My research interests lie in Machine Learning, Computer vision, and AGI. Currently, I am focusing on simulating Cognitive Baby Learning (Imagination, Reasoning, Attention)-->
<!--by using various learning algorithms (Representation Learning, Generative models, GNN, Reinforcement Learning,  Meta-Learning, etc.).</p>-->
<p> <b>Research opportunities</b>:<br>
	For USC undergraduate students: We have openings for interns through <a href=https://viterbiundergrad.usc.edu/research/curve/ target=_blank rel=noopener>CURVE</a> program. Usually we recruit students (first-time researchers and continuing researchers) during Fall and Spring semesters, please apply early. <br><br>
	For USC master students: Please directly email Prof. <a  target="_blank" href=https://people.ict.usc.edu/~soleymani/ target="_blank" rel="external">Mohammad Soleymani</a> for such inquiries. It would be better if you've attended CSCI 535 and obtained a good grade. <br><br>
	For all other students outside USC: we usually don't have openings during Fall and Spring semesters, but Prof. <a  target="_blank" href=https://people.ict.usc.edu/~soleymani/ target="_blank" rel="external">Mohammad Soleymani</a> sometimes recruits good candidates (Undergrad/Ms/visiting PhD) during the Summer. Email him for further details. <br><br>
	I am happy to collaborate and/or answer questions about my research and my previous study at TUM and current PhD program at USC. If you are interested in research collaboration or have any inquiries about my experience, please send me an email.
</p>





<h2><a id="C2" ><font color="#CB4335">News</font></a></h2>
<ul>

<div style="height:200px;width:fit-content;overflow:auto;background:#FFFFFF;">
	<li>
		<p>[2022/08/14] Our <a href=https://boese0601.github.io/fgnet/ target=_blank rel=noopener>FG-Net</a> and <a href=https://boese0601.github.io/fgnet/ target=_blank rel=noopener>LibreFace</a> has been accepted by WACV 2024! Find me at Waikoloa, Hawaii.</p>
	</li>
	<li>
		<p>[2023/05/22]  Start my Summer Internship at <a href="https://www.tiktok.com/en/">TikTok</a> (San Jose Office in CA). Looking forward to building connections with talents in the Bay Area! </p>
	</li>
	<li>
		<p>[2022/08/19]  Today I start my Ph.D. at <a href="https://www.cs.usc.edu/">USC Viterbi Computer Science</a>! Fight on, Trojans!  </p>
	</li>
	<li>
		<p>[2022/07/04]  My first single-first-author paper <a href=https://www.niessnerlab.org/projects/chang2022rcmvsnet.html target=_blank rel=noopener>RC-MVSNet</a> has been accepted by ECCV 2022! See you in Tel Aviv!</p>
	</li>
	<li>
		<p>[2022/04/08]  I'm joining <a href=https://www.ihp-lab.org/ target=_blank rel=noopener>IHP-Lab</a> at <a href=https://www.cs.usc.edu/ target=_blank rel=noopener>USC</a> as a PhD student, see you in Los Angeles!</p>
	</li>
	<li>
		<p>[2022/03/15] Our <a href=https://mizhenxing.github.io/gbinet/ target=_blank rel=noopener>GBi-Net</a> has been accepted by CVPR 2022!</p>
	<li>
		<p>[2022/03/07] I will join <a href=https://www.3dunderstanding.org target=_blank rel=noopener>3D AI Lab</a> at <a href=https://www.tum.de/en/ target=_blank rel=noopener>Technische Universität München</a> as a guided research student with Professor Angela Dai.</p>
	</li>
	<li>
		<p>[2022/01/15] I will join <a href=https://www.epfl.ch/labs/ivrl/ target=_blank rel=noopener>Image and Visual Representation Lab</a> at <a href=https://www.epfl.ch/en/ target=_blank rel=noopener>École Polytechnique Fédérale de Lausanne</a> as a research intern/visiting researcher.
	</li>
	<li>
		<p>[2021/10/15] I will join <a href=https://niessnerlab.org/ target=_blank rel=noopener>Visual Computing & Artificial Intelligence Lab</a> at <a href=https://www.tum.de/en/ target=_blank rel=noopener>Technische Universität München</a> with Professor Matthias Niessner.
	</li>
	<li>
		<p>[2021/03/04] I will join <a href=https://www.danxurgb.net/index.html target=_blank rel=noopener>Prof.Xu&rsquo;s vision group</a> at <a href=https://hkust.edu.hk/home target=_blank rel=noopener>HKUST</a> as a research intern during summer 2021.
	</li>
	

</div>
</ul>
<br>



<h2><a id="edu" ><font color="#CB4335">Education</font></a></h2>
<table>
	<tbody>
		<tr>
			<td width="800">
 
			<h4> University of Southern California, Los Angeles, USA <br>(Aug. 2022 - Present)</h4>
			<ul>
				<li>
				<b>Doctor of Philosophy in Computer Science</b></li>
				<li>Major Orientation: Deep Learning for 3D Vision and Affective Computing </li>
			</ul>
			</td>
<td>
	<img id="school_logo" src="./images/usc_cs_logo.jpeg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>



<table>
	<tbody>
		<tr>
			<td width="800">
 
 <h4> Technical University of Munich, Munich, Germany (Aug. 2021 - Jul. 2022)</h4>
 <ul>
	<li>
	  <b>Bachelor of Science in Informatics</b></li>
	<li>Major Orientation: Deep Learning for 3D Perception, 3D Scanning and Spatial Learning </li>
	<li>Overall GPA: 1.2/1.0 </li>
	<li>Bachelor thesis: "Supervised and Unsupervised Multi View Stereo for Depth Inference"</li>
 </ul>
</td>
<td>
	<img id="school_logo" src="./images/TUM.jpg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<table>
<tbody>
	<tr>
		<td width="800">
 <h4> Dalian University of Technology, Dalian, China (Sep. 2018 - Jul. 2021)</h4>
 <ul>
	<li>
	  <b>Bachelor of Engineering in Eletronic Information Engineering</b></li>
	<li>Major Orientation: Object Detection and Tracking</li>
	<li>Overall GPA: 91.5/100 | 3.93/4.0</li>
 </ul>
</td>
<td>
	<img id="school_logo" src="./images/DUT.jpg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<h2><a id="C3" ><font color="#CB4335">Preprints</font></a></h2>

<table id="tbPreprints" width="100%">


    <tr>
		<td width="306">
		<img src="images/magicdance.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>MagicDance: Realistic Human Dance Video Generation with Motions & Facial Expressions Transfer</b> <br>
			<br>
			<b>Di Chang</b>, <a href="https://seasonsh.github.io/">Yichun Shi</a>, <a href="https://zerg-overmind.github.io/">Quankai Gao</a>, <a href="https://www.linkedin.com/in/jessica-fu-60a504254/">Jessica Fu</a>, <a href="https://hongyixu37.github.io/homepage/">Hongyi Xu</a>, <a href="https://guoxiansong.github.io/homepage/index.html">Guoxian Song</a>, <a href="https://scholar.google.com/citations?user=0TIYjPAAAAAJ&hl=en">Qing Yan</a>, <a href="https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en">Xiao Yang</a>, <a href="https://www.ihp-lab.org/">Mohammad Soleymani</a><br>
		<em>Arxiv Preprint</em>
		<p></p>
		<p>
			[<a href="https://boese0601.github.io/magicdance/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2311.12052" target="_blank">paper</a>]
			[<a href="https://github.com/Boese0601/MagicDance" target="_blank">code</a>]
			[<a href="https://www.youtube.com/watch?v=VPJe6TyrT-Y" target="_blank">video</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

</table>
<br>


<h2><a id="C3" ><font color="#CB4335">Selected Publications</font></a> [<a href=https://scholar.google.com.hk/citations?hl=en&user=68wkMTgAAAAJ>Google Scholar</a>]</h2>

<table id="tbPublications" width="100%">


    <tr>
		<td width="306">
		<img src="images/libre.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>LibreFace: An Open-Source Toolkit for Deep Facial Expression Analysis</b> <br>
			<br>
			<b>Di Chang</b>, <a href=https://yufengyin.github.io/ target=_blank rel=noopener>Yufeng Yin</a>, Zongjian Li, <a href="https://scholar.google.com/citations?user=HuuQRj4AAAAJ&hl=en" target=_blank rel=noopener>Minh Tran</a>, and <a href=https://people.ict.usc.edu/~soleymani/ target=_blank rel=noopener>Mohammad Soleymani</a><br>
		<em>IEEE/CVF Winter Conference on Applications of Computer Vision</em> (<i><b>WACV</b></i>), 2024.  <b>(Application Track)</b>
		<p></p>
		<p>
			[<a href="https://boese0601.github.io/libreface/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2308.10713" target="_blank">paper</a>]
			[<a href="https://github.com/ihp-lab/LibreFace" target="_blank">code</a>]
			[<a href="" target="_blank">video</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="images/fgnet.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>FG-Net: Facial Action Unit Detection with Generalizable Pyramidal Features</b> <br>
			<br>
			<a href="https://yufengyin.github.io/" target=_blank rel=noopener>Yufeng Yin</a>, <b>Di Chang</b>,  <a href="https://guoxiansong.github.io/homepage/index.html" target=_blank rel=noopener>Guoxian Song</a>, <a href="https://ssangx.github.io/" target=_blank rel=noopener>Shen Sang</a>, <a href="https://tiancheng-zhi.github.io/" target=_blank rel=noopener>Tiancheng Zhi</a>, <a href="https://scholar.google.com/citations?user=fv8F6CEAAAAJ&hl=en" target=_blank rel=noopener>Jing Liu</a>, <a href="http://linjieluo.com/" target=_blank rel=noopener>Linjie Luo</a>, and <a href=https://people.ict.usc.edu/~soleymani/ target=_blank rel=noopener>Mohammad Soleymani</a><br>
		<em>IEEE/CVF Winter Conference on Applications of Computer Vision</em> (<i><b>WACV</b></i>), 2024.  <b>(Algorithms Track)</b>
		<p></p>
		<p>
			[<a href="" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2308.12380" target="_blank">paper</a>]
			[<a href="https://github.com/ihp-lab/FG-Net" target="_blank">code</a>]
			[<a href="" target="_blank">video</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="images/rc.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering</b> <br>
			<br>
			<b>Di Chang</b>, <a href=https://aljazbozic.github.io/ target=_blank rel=noopener>Aljaž Božic</a>, <a href="https://people.epfl.ch/tong.zhang?lang=en" target=_blank rel=noopener>Tong Zhang</a>, Qingsong Yan, Yingcong Chen, <a href=https://people.epfl.ch/sabine.susstrunk target=_blank rel=noopener>Sabine Süsstrunk</a> and <a href=https://niessnerlab.org/ target=_blank rel=noopener>Matthias Nießner</a><br>
			<!-- <b>Di Chang</b>, <a>Aljaž Božič, Tong Zhang, Qingsong Yan, Yingcong Chen, Sabine Süsstrunk and Matthias Nießner <br> -->
		<em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), 2022.
		<!-- <em>Arxiv Preprint</em> (<i><b>Under Review</b></i>), 2022. -->
		<p></p>
		<p>
			[<a href="https://boese0601.github.io/rc-mvsnet/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2203.03949" target="_blank">paper</a>]
			[<a href="https://github.com/Boese0601/RC-MVSNet" target="_blank">code</a>]
			[<a href="https://www.youtube.com/watch?v=I_Q47TxTLbs" target="_blank">video</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="images/gbinet.JPG" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Generalized Binary Search Network for Highly-Efficient Multi-View Stereo</b> <br>
			<br>
		<a href="https://mizhenxing.github.io/">Zhenxing Mi</a>, <b>Di Chang</b> and <a href="https://www.danxurgb.net/index.html">Dan Xu</a> <br>
		<em>IEEE/ CVF International Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2022.
		<p></p>
		<p>
			[<a href="https://mizhenxing.github.io/gbinet/" target="_blank">project page</a>]
			[<a href="https://arxiv.org/abs/2112.02338" target="_blank">paper</a>]
            [<a href="https://github.com/MiZhenxing/GBi-Net" target="_blank">code</a>]
		</p>

		<!-- <p><strong style="color:blue">Oral Presentation</strong></p> -->
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>




</table>
<br>

<h2><a id="C4" ><font color="#CB4335">Intern & Work Experience</font></a></h2>

<table>
	<tbody>
		<tr>
			<td width="800">
<h4>TikTok, Los Angeles, CA, USA (Aug. 2023 - Nov. 2023) </h4>
	  <ul>
        <li>Position: Research Scientist Intern (Part-time) at ByteDance AI Lab US</li>
		  <li>Supervisor: Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external"> Yichun Shi </a>, Dr. <a  target="_blank" href=https://guoxiansong.github.io/homepage/index.html rel="external"> Guoxian Song </a>, Dr. <a  target="_blank" href=https://hongyixu37.github.io/homepage/ rel="external"> Hongyi Xu </a>, and Dr. <a  target="_blank" href=https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en target="_blank" rel="external">Xiao Yang</a></li>
        <li>Project: Half-body Motion Transfer with Diffusion Models </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/TikTok.jpeg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<table>
	<tbody>
		<tr>
			<td width="800">
<h4>TikTok, San Jose, CA, USA (May. 2023 - Aug. 2023) </h4>
	  <ul>
        <li>Position: Research Scientist Intern at ByteDance AI Lab US</li>
		<li>Supervisor: Dr. <a  target="_blank" href=https://seasonsh.github.io/ rel="external"> Yichun Shi </a>, Dr. <a  target="_blank" href=https://guoxiansong.github.io/homepage/index.html rel="external"> Guoxian Song </a>, Dr. <a  target="_blank" href=https://hongyixu37.github.io/homepage/ rel="external"> Hongyi Xu </a>, and Dr. <a  target="_blank" href=https://scholar.google.com/citations?user=_MAKSLkAAAAJ&hl=en target="_blank" rel="external">Xiao Yang</a></li>
        <li>Project: Text-guided Half-body Image Editing with Diffusion Models </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/TikTok.jpeg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<table>
	<tbody>
		<tr>
			<td width="800">
<h4>EPFL, Lausanne, Switzerland (Jul. 2022 - Oct. 2022) </h4>
	  <ul>
        <li>Position: Summer@EPFL (Top 2% from the candidates in the world) hired by <a  target="_blank" href=https://www.epfl.ch/labs/ivrl/ target="_blank" rel="external">IVRL</a></li>
		  <li>Supervisor: Dr. <a  target="_blank" href=https://sites.google.com/view/tong-zhang rel="external"> Tong Zhang </a>
			and Prof. <a  target="_blank" href=https://people.epfl.ch/sabine.susstrunk?lang=en target="_blank" rel="external"> Sabine Süsstrunk</a></li>
        <li>Project: Video Synthesis with Diffusion Models </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/EPFL.png" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>
<!-- 
<table>
	<tbody>
		<tr>
			<td width="800">
	<h4> UCSD, San Diego, USA  (Remote Collaboration) </h4>
	<ul>
	  <li>Position: Research Intern in <a  target="_blank" href=https://xiaolonw.github.io/ target="_blank" rel="external">Prof. Wang's Group</a></li>
		<li>Supervisor: Prof. <a  target="_blank" href=https://xiaolonw.github.io/ target="_blank" rel="external"> Xiaolong Wang </a></li>
	  <li>Project: Video Synthesis with Diffusion Models <b>Ongoing Project</b> </li>
  </ul>
</td>
<td>
	<img id="school_logo" src="./images/UCSD.png" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table> -->

<!--    <img id="school_logo" src="./pics/uII.png">-->
<table>
	<tbody>
		<tr>
			<td width="800"> 
      <h4> TUM, Munich, Bayern, Germany  (Mar. 2022 - Aug. 2022) </h4>
	  <ul>
        <li>Position: Guided Research in <a  target="_blank" href=https://www.3dunderstanding.org target="_blank" rel="external">3D AI Group</a></li>
        <li>Supervisor: Prof. <a  target="_blank" href=https://www.3dunderstanding.org/team.html target="_blank" rel="external"> Angela Dai </a></li>
        <li>Project: Single-View Reconstruction and Category-level NeRF</li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/TUM.jpg" height="100px">
</td>
</tr>
<tr></tr>
</tbody></table>

<!--    <img id="school_logo" src="./pics/Flexiv.png">-->
          <!--<h4> The University of North Carolina at Chapel Hill, NC, USA  & <br> Shanghai United ImagingIntelligence Co., Ltd, China  (Jun. 2018 - Nov. 2018)</br> </h4>-->
		  <table>
			<tbody>
				<tr>
					<td width="800"> 
		  <h4> TUM, Munich, Bayern, Germany  (Aug. 2021 - Mar. 2022) </h4>
          <ul>
            <li>Position: Research Praktikum in <a  target="_blank" href="https://www.niessnerlab.org/" target="_blank" rel="external">Visual Computing Group</a></li>
            <li>Supervisor: Prof.<a  target="_blank" href=https://www.niessnerlab.org/members/matthias_niessner/profile.html target="_blank" rel="external"> Matthias Niessner</a> and
				M.Sc <a  target="_blank" href=https://aljazbozic.github.io/ target="_blank" rel="external"> Aljaž Božič </a>
			</li>
            <li>Project: Unsupervised Multi-View Stereo --> <b>ECCV 2022</b> </li>
            <!-- <br/>
            <br/> -->
            <!-- <td width="306">
            <img src="pics/masage.gif" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">
            </td> -->
      </ul>
	</td>
	<td>
		<img id="school_logo" src="./images/TUM.jpg" height="100px">
	</td>
	</tr>
	<tr></tr>
	</tbody></table>
<!--    <img id="school_logo" src="./pics/uII.png">-->
<table>
	<tbody>
		<tr>
			<td width="800">
      <h4> HKUST, Hong Kong, China  (Mar. 2021 - Sep. 2021) </h4>
	  <ul>
        <li>Position: Research Intern in <a  target="_blank" href="https://www.danxurgb.net/index.html" target="_blank" rel="external">HKUST Vision Group (MM-Lab at HKUST)</a></li>
        <li>Supervisor: Prof.<a  target="_blank" href=https://www.danxurgb.net/index.html target="_blank" rel="external"> Dan Xu</a>
        and M.Sc <a  target="_blank" href=https://mizhenxing.github.io/ target="_blank" rel="external"> Zhenxing Mi </a></li>
        <li>Project: Multi View Stereo Depth Estimation --> <b>CVPR 2022</b>  </li>
    </ul>
</td>
<td>
	<img id="school_logo" src="./images/HKUST.jpg" height="100px">
</td>
</tr>
<tr></tr>

</tbody></table>


<h2><font color="#CB4335">Students</font></h2>
      <ul>
		<li>
			<a  target="_blank" href=https://www.linkedin.com/in/jessica-fu-60a504254/ target="_blank" rel="external">Jessica Fu</a>. (Undergraduate student at USC, recruited through CURVE Fellowship. 2023 Fall)</li>		  
		<li>
			<a  target="_blank" href=https://www.linkedin.com/in/kevin-hopkins-1471781ba/ target="_blank" rel="external">Kevin Hopkins</a>. (Master student at USC. 2023 Fall)</li>
      </ul>

<br>

<h2><font color="#CB4335">Honors and Awards</font></h2>
      <ul>
        <!-- <li>
          Aug 2017 <b>The First Prize</b> 2017 ROBOMASTER <strong style="color:blue">The World’s Leading Robotics Competition</strong> (Responsible for the design
of electronic control in robotics)[<a  target="_blank" href="https://github.com/gyhandy/Andy">Code-T_Infantry</a>]</li>
		<li>
          Aug 2017 <b>Rank 1st</b> (preliminary competition) , Tianchi: Precision medical competition-Artificial Intelligence Aided
genetic risk prediction of diabetes [<a  target="_blank" href="https://github.com/gyhandy/Diabetes-Mellitus">Code-Pred_diabetes</a>]</li>
        <li>
          Oct 2015 <b>The First Prize</b> 9th international college students ican innovation and entrepreneurship contest</li> -->
		  
		<li>
			Mar 2022 <b>Outstanding UG graduates</b> of DUT </li>      
		<li>
			Oct 2021 <b>Outstanding Undergraduate</b> of DUT </li>     
        <li>
          May 2021 <b>The Third prize</b> 2021 China Underwater Robot Professional Contest - Acoustics Track </li>
		<li>
          May 2021 <b>The Second prize</b> 2021 China Underwater Robot Professional Contest - Optics Track </li>
		<li>
			Oct 2020 <b>Outstanding Undergraduate</b> of DUT </li>     
		<li>
			Oct 2019 <b>Outstanding Undergraduate</b> of DUT </li>        
      </ul>

<br>

<h2><font color="#CB4335">Academic Service</font></h2>
Reviewer of the following conferences/journals:
<br>
<br>
ECCV 2022<br>
NeurIPS 2022<br>
FG 2024<br>
CVPR 2024<br>
<!--2021 IEEE CVPR WORKSHOP ON FAIR, DATA EFFICIENT AND TRUSTED COMPUTER VISION<br>-->


<br>


<h2><font color="#CB4335">Teaching</font></h2>
      <ul>
		<li>
			Graduate Teaching Assistant, CSCI 103 Introduction to Programming - 2022 Fall</li>
		<li>
			Graduate Teaching Assistant, CSCI 535 Introduction to Programming - 2024 Spring</li>
        <!-- <li>
          Sep 2017 <b>National Scholarship(Graduate)</b>, (highest honor for graduates) <strong style="color:blue">top 1% nationwide</strong></li>
        <li>
          Sep 2015 <b>National Scholarship(Undergraduate)</b>, (highest honor for undergraduates, top 2% nationwide) </li>
		<li>
          May 2018 <b>KaiYuan Motivational Scholarship</b> <strong style="color:blue">top 0.5% in Shanghai Jiao Tong University</strong></li>
        <li>
          Sep 2015 <b>Presidential Scholarship</b>, (highest honor in Shandong University) <strong style="color:blue">top 0.2% in Shan Dong University</strong></li>
        <li>
          Sep 2015 <b>BaoGang Excellent student Scholarship</b>, (4 Places per year at Shandong University) </li>
		<li>
          Sep 2015 &amp; Sep 2014 &amp; Sep 2015</b> <b>First Prize Scholarship</b> (Top 6% in China,three-year continuous)</li> -->
      </ul>

<br>

<h2><font color="#CB4335">Miscellaneous</font></h2>
      <ul>
		<li>
			(10 yrs +) 🎷Clarinet, professional player, once level 9 certification of The Central Conservatory of Music.</li>		  
		<li>
			(8 yrs +) 🏸Badminton, I was a member of DUT EE Department badminton team.</li>
		<li>
			(5 yrs +) 🎮Video Games, I am a lover of League of Legends, highest rank: Platinum II of EU server S12.</li>
		<li>
			(New Hobby) 🏁Car Racing, I love racing with my Chevy Camaro SS. Find me in LA on weekends!</li>
      </ul>

<br>




<div id="footer1">
	<h2> </h2>
		<div align="center">
		  <small>This page has been visited for
			<a href="https://www.easycounter.com/">
			<img src="https://www.easycounter.com/counter.php?dichang" border="0" alt="HTML Hit Counter"></a>times</small>
		  </div> 
	</div>
  <p>
	<center>
	<div align="center" style="width:20%">
	  <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=grr8tSJTdsbdU-vHO6Of-5W7jpLTZvSVYTu6BUgf02M"></script>
	</div>        
	</center>
  </p>
  

<p align="center"><font color="#999999">Last update: Apr. 10, 2022</font></p>



</body>

</html>
